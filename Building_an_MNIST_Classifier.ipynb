{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an MNIST Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xf2/Pytorch-scratch/blob/master/Building_an_MNIST_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BTIAeOuhwa"
      },
      "source": [
        "## NOTE: Click the top-left \"Open In Playground\" button! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b1o-YeTJDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e5336e-4aac-42cf-f0b9-2406c95fd727"
      },
      "source": [
        "# install basical image libs\n",
        "!pip install Pillow>=5.0.0\n",
        "!pip install -U image\n",
        "\n",
        "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
        "from os.path import exists\n",
        "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: image in /usr/local/lib/python3.6/dist-packages (1.5.33)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from image) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: django in /usr/local/lib/python3.6/dist-packages (from image) (3.1.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from image) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: asgiref<4,>=3.2.10 in /usr/local/lib/python3.6/dist-packages (from django->image) (3.3.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlparse>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from django->image) (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13PbnpgoQNha"
      },
      "source": [
        "## Building an MNIST Classifier\n",
        "\n",
        "\n",
        "Using what we have learned, let's build a simple MNIST digits classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0tjLy2VUkj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f6eG5KSOKw"
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "The [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html) library provides a wide range of standard vision datasets and networks with pretrained weights. We will use [the `torchvision.datasets.MNIST` class](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) to easily access the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YutSDfPfR_Eg"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGQ7wf5S-g7"
      },
      "source": [
        "Each element of the dataset is a 2-tuple, consisting of the image of the digit, and its label. E.g.,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpK3WQnMSxDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "87fef241-d7e0-4998-ae7b-421eb08f6c1f"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print('This is a digit {}:'.format(label))\n",
        "image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a digit 6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+UlEQVR4nNWPoUtDYRTFTxC0CIJhQcS0l8aYGPSF8TBOhWX/gxXZUxSbQcOKzVWbJmGMLQ/TXDVtZbyhbGEWnwtazvEzCML7tq+teNLl/rjnngPMTV704mQ3b6w7UKotPq86LBvU2a7j0Cd16MwiFV1hrthcc7Gnz346uVn4m4rb5uHLAVfywPsQQHkdp7bp8qPRDnByHEnGfn1ADdLI1chJV52N5OERh5fw7jW+2wzUTcICeYFUg3F1MdOLq0nXcxJokwF88tp6WVENuZFCeJHCqSrGAN8m+7o0yH/YTXzSL8Wkxns2ArYmFEnaWX613xJ5Gwaz2P/QDwv6bXmT2FBqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FD3B6856CF8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7XDKYoTKER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2719645f-0c15-4325-8791-7c7ffdad60e2"
      },
      "source": [
        "type(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDgAtpx9TaJk"
      },
      "source": [
        "The image is given as a `PIL.Image`. To automatically obtain a `torch.Tensor`, we can add a [`torchvision.transforms.ToTensor` ](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor) transform when constructing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLnprU5TcPW"
      },
      "source": [
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=torchvision.transforms.ToTensor())  # the ToTensor transform converts PIL.Image to torch.Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_S3CyfdTvYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9801e2-e623-4c9e-e586-8c8e1187bca9"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print(type(image))\n",
        "print(image.shape)  # MNIST images are 28x28, and have a single channel representing brightness."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxpkn2MTw8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d117e2-4721-4da2-90e3-f373ebe40e12"
      },
      "source": [
        "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image has max=1.0 and min=0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlxkKkiUbT9"
      },
      "source": [
        "In deep learning, it is often a good idea to normalize network inputs to be centered around zero. We use the [`torchvision.transforms.Normalize`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) tranform to achieve this. Adding this transform, we construct the dataset as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUana9IuVQ_l"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
        "])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=transform)\n",
        "mnist_val = torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
        "                                         transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6732k7jSDze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1396737-5c1e-479a-ef08-a16008adda1f"
      },
      "source": [
        "print('training set size:\\t{}'.format(len(mnist_train)))\n",
        "print('validation set size:\\t{}'.format(len(mnist_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set size:\t60000\n",
            "validation set size:\t10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_zABI6VzqM"
      },
      "source": [
        "We use the PyTorch `torch.utils.data.DataLoader` to automatically load batched data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfqlx7jDUK_C"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True,                   # shuffle training set\n",
        "                                           num_workers=4,                  # turns on multi-processing loading so training is not blocked by data loading\n",
        "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
        "val_loader = torch.utils.data.DataLoader(mnist_val, \n",
        "                                         batch_size=batch_size, \n",
        "                                         num_workers=4, \n",
        "                                         pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwhWLUYa_jj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc55e591-eca4-41e8-ef9d-d05f45ed455c"
      },
      "source": [
        "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple, \n",
        "# but now consisting of a batched image tensor, and a batched label tensor.\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print('batched image tensor shape: {}'.format(images.shape))\n",
        "print('batched label tensor shape: {}'.format(labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batched image tensor shape: torch.Size([512, 1, 28, 28])\n",
            "batched label tensor shape: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vtmrt4RWkYi"
      },
      "source": [
        "### Building the Network\n",
        "\n",
        "We will use a convolutional network for classification. The following architecture is adapted from the famous [LeNet-5](https://ieeexplore.ieee.org/document/726791) [1].\n",
        "\n",
        "\n",
        "\n",
        "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGKK2QIWgyI"
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = self.conv3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h260SpqhYkGL"
      },
      "source": [
        "net = MyNet().to(cuda0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQCUclhOZ4zS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d07ae3-fea8-4014-8ed8-2e1c69a7bc99"
      },
      "source": [
        "# This network output a size 10 vector for each input image, as verified below \n",
        "# using a random input tensor.\n",
        "\n",
        "net(torch.randn(32, 1, 28, 28, device=cuda0)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2horeRUtaD7R"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "\n",
        "For classification, we will use the cross-entropy loss [`F.cross_entropy`](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy) to train this network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPbQzcJbvnj"
      },
      "source": [
        "We can write a function that iterates through the training set (via `train_loader`) and train for 1 epoch. The code is extremely similar to what we did for approximating $f(x) = \\cos(x)$, only with new ways to load data and compute loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BrV5UGaIXj"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def train(net, optim):\n",
        "    net.train()\n",
        "    for image, label in train_loader:\n",
        "        # put data onto GPU\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # clear gradient\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # forward through the network\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # compute loss and gradient\n",
        "        # FIXME!!! Check the `F.cross_entropy` documentation linked above\n",
        "        \n",
        "        # update parameters\n",
        "        # FIXME!!!\n",
        "        \n",
        "        pass  # FIXME!!! Remove this `pass` when you are done."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_TGTEcj2J"
      },
      "source": [
        "Let's also write a function that evaluates our network on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wHW_UObnAk"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def evaluate(net):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    net.eval()  # puts the network in eval mode. this is important when the \n",
        "                # network has layers that behaves differently in training and \n",
        "                # evaluation time, e.g., dropout and batch norm.\n",
        "    for image, label in val_loader:\n",
        "        # put data onto GPU\n",
        "        # FIXME!!!\n",
        "        \n",
        "        with torch.no_grad():  # gradients are not tracked in this context manager\n",
        "                               # since we are evaluating, gradients are not needed \n",
        "                               # and we can save some time and GPU memory.\n",
        "              \n",
        "            # forward through the network, and get the predicted class\n",
        "            # FIXME!!!  (HINT: use .argmax(dim=-1))\n",
        "            #   `prediction` should be an integer vector of size equal to the batch size.\n",
        "            #   Remember that the network outputs logits of the prediction probabilities, \n",
        "            #   and that the higher the logits, the higher the probability.\n",
        "            prediction = None  \n",
        "            \n",
        "            total += image.size(0)  # batch size\n",
        "            correct += (prediction == label).sum().item()  # `.item()` retreives a python number from a 1-element tensor\n",
        "            \n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7PVIwJdrKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11a1ef8-c65d-440e-99c3-9cd38319a4d2"
      },
      "source": [
        "# Without any training, the network accuracy matches that of random guessing: ~10%.\n",
        "\n",
        "print('At initialization, the network has accuracy {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At initialization, the network has accuracy 9.7300%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOd5vtSOeI1T"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7n0x8idsDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843ac038-c3ff-4cd8-8ea7-399cf5cb3f95"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 0.1\n",
        "\n",
        "optim = None  # FIXME!!! Construct an optimizer (e.g., SGD) to optimize the network parameters with the above learning rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: {}\\tValidation Accuracy: {:.4f}%'.format(epoch, evaluate(net) * 100))\n",
        "    train(net, optim)\n",
        "\n",
        "print('Done! \\tValidation Accuracy: {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\tValidation Accuracy: 9.7300%\n",
            "Epoch: 1\tValidation Accuracy: 65.4300%\n",
            "Epoch: 2\tValidation Accuracy: 83.5600%\n",
            "Epoch: 3\tValidation Accuracy: 86.9800%\n",
            "Epoch: 4\tValidation Accuracy: 80.4700%\n",
            "Epoch: 5\tValidation Accuracy: 83.7900%\n",
            "Epoch: 6\tValidation Accuracy: 91.6700%\n",
            "Epoch: 7\tValidation Accuracy: 85.4100%\n",
            "Epoch: 8\tValidation Accuracy: 91.9300%\n",
            "Epoch: 9\tValidation Accuracy: 89.9600%\n",
            "Done! \tValidation Accuracy: 91.8700%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEuCz50os93"
      },
      "source": [
        "## Open-ended Exercises (not required)\n",
        "\n",
        "1. What could you do to make the accuracy higher and/or the training faster?  \n",
        "2. Adapt the code for another dataset (e.g., CIFAR-10 from [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)).\n",
        "3. How dose your MNIST perform on [the USPS dataset](https://gist.github.com/SsnL/300865932b090d3f0798c2b961d371f9) (another black-white digits dataset)? Why?\n",
        "4. How many samples are actually needed to train a good MNIST classifier? Try subsample the training set (sampled a fraction of images per class) and plot validation accuracy vs. training set size.\n",
        "5. Use the [fast-gradient sign method](https://arxiv.org/abs/1412.6572) to attack your MNIST classifier! Why does your super great classifier now fail at a seemingly normal digit image?"
      ]
    }
  ]
}